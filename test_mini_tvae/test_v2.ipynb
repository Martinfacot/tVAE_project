{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test mini_tVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('/home/mfacotti/martin/tVAE_project')\n",
    "from mini_tvae_v2 import MiniTVAE\n",
    "from data_load import DataLoader\n",
    "\n",
    "\n",
    "from sdv.evaluation.single_table import run_diagnostic, evaluate_quality\n",
    "from sdv.metadata import Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected missing values in 5 columns:\n",
      "  - cat2: 4535 missing values (79.1%)\n",
      "  - dschdte: 1 missing values (0.0%)\n",
      "  - dthdte: 2013 missing values (35.1%)\n",
      "  - adld3p: 4296 missing values (74.9%)\n",
      "  - urin1: 3028 missing values (52.8%)\n",
      "No discrete columns found in metadata. Inferring from data types...\n",
      "Loaded dataset with 5735 rows and 63 columns\n",
      "Identified 21 discrete columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>ca</th>\n",
       "      <th>sadmdte</th>\n",
       "      <th>dschdte</th>\n",
       "      <th>dthdte</th>\n",
       "      <th>lstctdte</th>\n",
       "      <th>death</th>\n",
       "      <th>cardiohx</th>\n",
       "      <th>...</th>\n",
       "      <th>meta</th>\n",
       "      <th>hema</th>\n",
       "      <th>seps</th>\n",
       "      <th>trauma</th>\n",
       "      <th>ortho</th>\n",
       "      <th>adld3p</th>\n",
       "      <th>urin1</th>\n",
       "      <th>race</th>\n",
       "      <th>income</th>\n",
       "      <th>ptid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>COPD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11142</td>\n",
       "      <td>11151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11382</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>Under $11k</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MOSF w/Sepsis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>11799</td>\n",
       "      <td>11844.0</td>\n",
       "      <td>11844.0</td>\n",
       "      <td>11844</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>white</td>\n",
       "      <td>Under $11k</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MOSF w/Malignancy</td>\n",
       "      <td>MOSF w/Sepsis</td>\n",
       "      <td>Yes</td>\n",
       "      <td>12083</td>\n",
       "      <td>12143.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12400</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>599.0</td>\n",
       "      <td>white</td>\n",
       "      <td>$25-$50k</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ARF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>11146</td>\n",
       "      <td>11183.0</td>\n",
       "      <td>11183.0</td>\n",
       "      <td>11182</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>$11-$25k</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MOSF w/Sepsis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>12035</td>\n",
       "      <td>12037.0</td>\n",
       "      <td>12037.0</td>\n",
       "      <td>12036</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>white</td>\n",
       "      <td>Under $11k</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               cat1           cat2   ca  sadmdte  dschdte  \\\n",
       "0           1               COPD            NaN  Yes    11142  11151.0   \n",
       "1           2      MOSF w/Sepsis            NaN   No    11799  11844.0   \n",
       "2           3  MOSF w/Malignancy  MOSF w/Sepsis  Yes    12083  12143.0   \n",
       "3           4                ARF            NaN   No    11146  11183.0   \n",
       "4           5      MOSF w/Sepsis            NaN   No    12035  12037.0   \n",
       "\n",
       "    dthdte  lstctdte death  cardiohx  ...  meta  hema  seps  trauma  ortho  \\\n",
       "0      NaN     11382    No         0  ...    No    No    No      No     No   \n",
       "1  11844.0     11844   Yes         1  ...    No    No   Yes      No     No   \n",
       "2      NaN     12400    No         0  ...    No    No    No      No     No   \n",
       "3  11183.0     11182   Yes         0  ...    No    No    No      No     No   \n",
       "4  12037.0     12036   Yes         0  ...    No    No    No      No     No   \n",
       "\n",
       "   adld3p   urin1   race      income  ptid  \n",
       "0     0.0     NaN  white  Under $11k     5  \n",
       "1     NaN  1437.0  white  Under $11k     7  \n",
       "2     NaN   599.0  white    $25-$50k     9  \n",
       "3     NaN     NaN  white    $11-$25k    10  \n",
       "4     NaN    64.0  white  Under $11k    11  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(\n",
    "    csv_filename='../rhc.csv',\n",
    "    meta_filename='../metadata.json'\n",
    ")\n",
    "data, discrete_columns = data_loader.load_data()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Mini TVAE model with the following parameters:\n",
      "  embedding_dim: 128\n",
      "  compress_dims: (128, 128)\n",
      "  decompress_dims: (128, 128)\n",
      "  l2scale: 1e-05\n",
      "  batch_size: 500\n",
      "  epochs: 1000\n",
      "  loss_factor: 2\n",
      "  cuda: True\n",
      "  verbose: True\n",
      "Note: Found NaN values in columns: ['cat2', 'dschdte', 'dthdte', 'adld3p', 'urin1']. These will be handled using the 'from_column' approach.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "/home/mfacotti/.local/lib/python3.10/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning:\n",
      "\n",
      "Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "\n",
      "Loss: 0.000:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (500x401 and 400x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# add feature to save model\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_tvae_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_columns\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m, in \u001b[0;36mtrain_tvae_model\u001b[0;34m(data, discrete_columns, hyperparams)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Create and train the model\u001b[39;00m\n\u001b[1;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m MiniTVAE(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/martin/tVAE_project/test_mini_tvae/mini_tvae_v2.py:192\u001b[0m, in \u001b[0;36mMiniTVAE.fit\u001b[0;34m(self, train_data, discrete_columns)\u001b[0m\n\u001b[1;32m    190\u001b[0m optimizerAE\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    191\u001b[0m real \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_device)\n\u001b[0;32m--> 192\u001b[0m mu, std, logvar \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m eps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(std)\n\u001b[1;32m    194\u001b[0m emb \u001b[38;5;241m=\u001b[39m eps \u001b[38;5;241m*\u001b[39m std \u001b[38;5;241m+\u001b[39m mu\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/martin/tVAE_project/test_mini_tvae/mini_tvae_v2.py:28\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_):\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Encode the passed `input_`.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     mu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(feature)\n\u001b[1;32m     30\u001b[0m     logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(feature)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (500x401 and 400x128)"
     ]
    }
   ],
   "source": [
    "def train_tvae_model(data, discrete_columns, hyperparams=None):\n",
    "    \"\"\"\n",
    "    Create and train a MiniTVAE model with the provided hyperparameters.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        The training data\n",
    "    discrete_columns : list\n",
    "        List of discrete/categorical columns\n",
    "    hyperparams : dict, optional\n",
    "        Dictionary of hyperparameters for the MiniTVAE model\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    MiniTVAE\n",
    "        The trained model\n",
    "    \"\"\"\n",
    "    # Default hyperparameters\n",
    "    default_params = {\n",
    "        'embedding_dim': 128,\n",
    "        'compress_dims': (128, 128),\n",
    "        'decompress_dims': (128, 128),\n",
    "        'l2scale': 1e-5,\n",
    "        'batch_size': 500,\n",
    "        'epochs': 1000,\n",
    "        'loss_factor': 2,\n",
    "        'cuda': True, # Set to False if running on CPU\n",
    "        'verbose': True\n",
    "    }\n",
    "    \n",
    "    # Use provided hyperparameters or default values\n",
    "    params = default_params.copy()\n",
    "    if hyperparams:\n",
    "        params.update(hyperparams)\n",
    "    \n",
    "    print(\"Training Mini TVAE model with the following parameters:\")\n",
    "    for key, value in params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Create and train the model\n",
    "    model = MiniTVAE(**params)\n",
    "    model.fit(data, discrete_columns)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# add feature to save model\n",
    "model = train_tvae_model(data, discrete_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_over_epochs(loss_values):\n",
    "    \"\"\"Plot the loss components across epochs.\"\"\"\n",
    "    # Group by epoch and calculate mean loss components per epoch\n",
    "    epoch_loss = loss_values.groupby('Epoch')[['loss_1', 'loss_2', 'total_loss']].mean().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(18, 6))\n",
    "    \n",
    "    # Plot mean loss components per epoch\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epoch_loss['Epoch'], epoch_loss['loss_1'], 'b-', label='Reconstruction Loss')\n",
    "    plt.plot(epoch_loss['Epoch'], epoch_loss['loss_2'], 'r-', label='KL Divergence')\n",
    "    plt.plot(epoch_loss['Epoch'], epoch_loss['total_loss'], 'g-', label='Total Loss')\n",
    "    plt.title('Mean Loss Components per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot batch reconstruction losses across epochs\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for epoch in sorted(loss_values['Epoch'].unique()):\n",
    "        epoch_data = loss_values[loss_values['Epoch'] == epoch]\n",
    "        plt.scatter([epoch] * len(epoch_data), epoch_data['loss_1'], \n",
    "                    alpha=0.3, s=10, color='blue')\n",
    "    plt.title('Reconstruction Loss per Batch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot batch KL divergence losses across epochs\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for epoch in sorted(loss_values['Epoch'].unique()):\n",
    "        epoch_data = loss_values[loss_values['Epoch'] == epoch]\n",
    "        plt.scatter([epoch] * len(epoch_data), epoch_data['loss_2'], \n",
    "                    alpha=0.3, s=10, color='red')\n",
    "    plt.title('KL Divergence per Batch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plot_loss_over_epochs(model.loss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(model, num_samples, save_path=None):\n",
    "    \"\"\"\n",
    "    Generate synthetic data from the trained model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : MiniTVAE\n",
    "        The trained model\n",
    "    num_samples : int\n",
    "        Number of samples to generate\n",
    "    save_path : str, optional\n",
    "        Path to save the synthetic data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        The generated synthetic data\n",
    "    \"\"\"\n",
    "    print(f\"Generating {num_samples} synthetic samples...\")\n",
    "    synthetic_data = model.sample(num_samples)\n",
    "    \n",
    "    if save_path:\n",
    "        synthetic_data.to_csv(save_path, index=False)\n",
    "        print(f\"Synthetic data saved to '{save_path}'\")\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "generate_synthetic_data(model, 10000, 'synthetic_rhc.csv') # or fit the number of samples to the original dataset with len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_statistics(original_data, synthetic_data, discrete_columns, \n",
    "                       num_numeric=5, num_categorical=3, num_categories=5, \n",
    "                       exclude_first_column=True):\n",
    "    \"\"\"\n",
    "    Compare statistics between original and synthetic data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    original_data : DataFrame\n",
    "        The original data\n",
    "    synthetic_data : DataFrame\n",
    "        The synthetic data\n",
    "    discrete_columns : list\n",
    "        List of discrete/categorical columns\n",
    "    num_numeric : int, optional\n",
    "        Number of numeric columns to compare\n",
    "    num_categorical : int, optional\n",
    "        Number of categorical columns to compare\n",
    "    num_categories : int, optional\n",
    "        Number of categories to display per categorical column\n",
    "    exclude_first_column : bool, optional\n",
    "        Whether to exclude the first column (patient ID) from the comparison\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing statistical comparison metrics\n",
    "    \"\"\"\n",
    "    print(\"Comparing statistics between original and synthetic data:\")\n",
    "    \n",
    "    # Create a copy of the dataframes to avoid modifying the originals\n",
    "    orig_data = original_data.copy()\n",
    "    synth_data = synthetic_data.copy()\n",
    "    \n",
    "    # Exclude the first column (patient ID) if requested\n",
    "    if exclude_first_column:\n",
    "        first_col = orig_data.columns[0]\n",
    "        print(f\"Excluding first column (patient ID): {first_col}\")\n",
    "        orig_data = orig_data.drop(columns=[first_col])\n",
    "        if first_col in synth_data.columns:\n",
    "            synth_data = synth_data.drop(columns=[first_col])\n",
    "    \n",
    "    # Initialize results dictionary to store comparison metrics\n",
    "    results = {\n",
    "        'numeric': {},\n",
    "        'categorical': {}\n",
    "    }\n",
    "    \n",
    "    # Compare numeric columns\n",
    "    numeric_columns = orig_data.select_dtypes(include=['number']).columns\n",
    "    if len(numeric_columns) > 0:\n",
    "        print(\"\\nNumeric columns comparison:\")\n",
    "        for col in numeric_columns[:num_numeric]:\n",
    "            # Calculate statistics for original data\n",
    "            orig_mean = orig_data[col].mean()\n",
    "            orig_std = orig_data[col].std()\n",
    "            orig_min = orig_data[col].min()\n",
    "            orig_max = orig_data[col].max()\n",
    "            \n",
    "            # Calculate statistics for synthetic data\n",
    "            syn_mean = synth_data[col].mean()\n",
    "            syn_std = synth_data[col].std()\n",
    "            syn_min = synth_data[col].min()\n",
    "            syn_max = synth_data[col].max()\n",
    "            \n",
    "            # Calculate differences\n",
    "            mean_diff = abs(orig_mean - syn_mean)\n",
    "            std_diff = abs(orig_std - syn_std)\n",
    "            \n",
    "            # Store results\n",
    "            results['numeric'][col] = {\n",
    "                'original': {'mean': orig_mean, 'std': orig_std, 'min': orig_min, 'max': orig_max},\n",
    "                'synthetic': {'mean': syn_mean, 'std': syn_std, 'min': syn_min, 'max': syn_max},\n",
    "                'difference': {'mean': mean_diff, 'std': std_diff}\n",
    "            }\n",
    "            \n",
    "            # Print comparison\n",
    "            print(f\"\\nColumn: {col}\")\n",
    "            print(f\"  Original - Mean: {orig_mean:.4f}, Std: {orig_std:.4f}, Range: [{orig_min:.4f}, {orig_max:.4f}]\")\n",
    "            print(f\"  Synthetic - Mean: {syn_mean:.4f}, Std: {syn_std:.4f}, Range: [{syn_min:.4f}, {syn_max:.4f}]\")\n",
    "            print(f\"  Difference - Mean: {mean_diff:.4f}, Std: {std_diff:.4f}\")\n",
    "    \n",
    "    # Compare categorical columns\n",
    "    valid_discrete_columns = [col for col in discrete_columns if col in orig_data.columns]\n",
    "    if len(valid_discrete_columns) > 0:\n",
    "        print(\"\\nCategorical columns comparison (value counts percentage):\")\n",
    "        for col in valid_discrete_columns[:num_categorical]:\n",
    "            print(f\"\\nColumn: {col}\")\n",
    "            \n",
    "            # Calculate distributions\n",
    "            orig_counts = orig_data[col].value_counts(normalize=True).sort_index()\n",
    "            syn_counts = synth_data[col].value_counts(normalize=True).sort_index()\n",
    "            \n",
    "            # Combine indices to ensure we show all categories\n",
    "            all_cats = sorted(list(set(list(orig_counts.index) + list(syn_counts.index))))\n",
    "            cat_results = {}\n",
    "            \n",
    "            # Print and store category comparisons\n",
    "            for cat in all_cats[:num_categories]:\n",
    "                orig_pct = orig_counts.get(cat, 0) * 100\n",
    "                syn_pct = syn_counts.get(cat, 0) * 100\n",
    "                diff_pct = abs(orig_pct - syn_pct)\n",
    "                \n",
    "                cat_results[cat] = {\n",
    "                    'original': orig_pct,\n",
    "                    'synthetic': syn_pct,\n",
    "                    'difference': diff_pct\n",
    "                }\n",
    "                \n",
    "                print(f\"  {cat}: Original {orig_pct:.1f}%, Synthetic {syn_pct:.1f}%, Diff {diff_pct:.1f}%\")\n",
    "            \n",
    "            # Store results for this column\n",
    "            results['categorical'][col] = cat_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "stats = compare_statistics(data, generate_synthetic_data(model, len(data)), discrete_columns, exclude_first_column=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../rhc.csv')\n",
    "metadata = Metadata.load_from_json('../metadata.json')\n",
    "\n",
    "# Load the synthetic data\n",
    "synthetic_data = pd.read_csv('synthetic_rhc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic = run_diagnostic(\n",
    "    real_data=data,\n",
    "    synthetic_data=synthetic_data,\n",
    "    metadata=metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_report = evaluate_quality(\n",
    "    data,\n",
    "    synthetic_data,\n",
    "    metadata\n",
    ")\n",
    "\n",
    "# quality_report.save(filepath='results/diagnostic_report.pkl')\n",
    "# quality_report = QualityReport.load('results/quality_report.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_report.get_details('Column Shapes')\n",
    "# KSComplement for numerical columns\n",
    "# TVComplement for categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_report.get_details('Column Pair Trends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = quality_report.get_visualization('Column Pair Trends')\n",
    "fig2 = quality_report.get_visualization('Column Shapes')\n",
    "\n",
    "fig1.show()\n",
    "fig2.show() # This one is not working properly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
